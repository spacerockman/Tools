import subprocess
import os
import sys
import zipfile
import io
import time
import requests
import numpy as np
import cv2 # éœ€è¦ opencv-contrib-python

# ================= âš™ï¸ é…ç½®åŒºåŸŸ =================

KCC_PATH = r"C:\Program Files\kindleComicConverter\kcc_c2e_9.2.2.exe"
INPUT_DIR = r"D:\BaiduNetdiskDownload\onedrive\Desktop\workspace\Tools\pdf-coverter-to-comic\inputs"
OUTPUT_DIR = r"D:\BaiduNetdiskDownload\onedrive\Desktop\workspace\Tools\pdf-coverter-to-comic\outputs"
DEVICE_PROFILE = 'KO' 

# --- AI & å›¾åƒå‚æ•° ---

# 1. ç›®æ ‡å®½åº¦ï¼šKindle 12ä»£ç‰©ç†æé™
TARGET_WIDTH = 1264

# 2. Gamma å€¼ï¼šAI é‡ç»˜åçº¿æ¡ä¼šå˜æ¸…æ™°ï¼Œ1.4 çš„ Gamma èƒ½è®©é»‘è‰²æ›´æ‰å®
GAMMA_VALUE = 1.4

# 3. å‹ç¼©è´¨é‡ï¼šé…åˆ AI é™å™ªåçš„çº¯å‡€ç”»é¢ï¼Œ60 ä¾ç„¶å®Œç¾
JPEG_QUALITY = 60

# 4. AI æ¨¡å‹è·¯å¾„ (è„šæœ¬ä¼šè‡ªåŠ¨ä¸‹è½½ï¼Œæ— éœ€æ‰‹åŠ¨å¯»æ‰¾)
MODEL_NAME = "FSRCNN_x2.pb"
MODEL_URL = "https://github.com/Saafke/FSRCNN_Tensorflow/raw/master/models/FSRCNN_x2.pb"

# ===============================================

def check_and_download_model():
    """æ£€æŸ¥ AI æ¨¡å‹æ˜¯å¦å­˜åœ¨ï¼Œä¸å­˜åœ¨åˆ™è‡ªåŠ¨ä¸‹è½½"""
    if not os.path.exists(MODEL_NAME):
        print(f"â¬‡ï¸ æ­£åœ¨ä¸‹è½½ç¥ç»ç½‘ç»œæ¨¡å‹ ({MODEL_NAME})...")
        try:
            response = requests.get(MODEL_URL, stream=True)
            if response.status_code == 200:
                with open(MODEL_NAME, 'wb') as f:
                    f.write(response.content)
                print("âœ… æ¨¡å‹ä¸‹è½½å®Œæˆï¼")
            else:
                print("âŒ æ¨¡å‹ä¸‹è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œã€‚")
                sys.exit(1)
        except Exception as e:
            print(f"âŒ ä¸‹è½½å‡ºé”™: {e}")
            sys.exit(1)

def run_kcc_conversion(input_path, output_path):
    print(f"   [1/2] KCC ç»“æ„è½¬æ¢...")
    cmd = [
        KCC_PATH, input_path,
        '-m', '-s', 
        '-g', '1.0', 
        '--format=EPUB', '-p', DEVICE_PROFILE, 
        '--output', output_path
    ]
    try:
        subprocess.run(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, check=True)
        return True
    except:
        return False

# åˆå§‹åŒ– AI è¶…åˆ†å¯¹è±¡ (å…¨å±€å¤ç”¨ï¼Œæé«˜é€Ÿåº¦)
sr = cv2.dnn_superres.DnnSuperResImpl_create()
model_loaded = False

def neural_enhance_image(img_bytes):
    """
    ğŸ§  æ ¸å¿ƒç®—æ³•ï¼šAI é‡ç»˜ (FSRCNN) + ç‰©ç†ç¼©æ”¾ + Gamma
    """
    global model_loaded, sr
    
    # 1. è§£ç ä¸º OpenCV æ ¼å¼
    nparr = np.frombuffer(img_bytes, np.uint8)
    img = cv2.imdecode(nparr, cv2.IMREAD_GRAYSCALE) # ç›´æ¥è¯»ä¸ºç°åº¦ï¼Œçœæµ
    
    if img is None: return img_bytes

    # --- æ­¥éª¤ A: ç¥ç»ç½‘ç»œé‡ç»˜ (AI Super Resolution) ---
    # åªæœ‰å½“å›¾ç‰‡ä¸æ˜¯ç‰¹åˆ«å·¨å¤§çš„æ—¶å€™æ‰å¯ç”¨ AIï¼Œå¦åˆ™é€Ÿåº¦ä¼šå¤ªæ…¢
    # FSRCNN é€Ÿåº¦å¾ˆå¿«ï¼Œä½†å¦‚æœåŸå›¾å·²ç»æ˜¯ 4000px å®½ï¼Œå†æ”¾å¤§ 2 å€å†…å­˜ä¼šçˆ†
    h, w = img.shape[:2]
    
    # åŠ è½½æ¨¡å‹ (åªåŠ è½½ä¸€æ¬¡)
    if not model_loaded:
        sr.readModel(MODEL_NAME)
        sr.setModel("fsrcnn", 2) # 2å€æ”¾å¤§
        model_loaded = True
    
    # ç­–ç•¥ï¼šå¦‚æœå›¾ç‰‡å®½åº¦å°äº 1500ï¼Œæˆ‘ä»¬ç”¨ AI æ”¾å¤§é‡ç»˜
    # è¿™èƒ½æå¤§æ”¹å–„ä½åˆ†è¾¨ç‡æ‰«æä»¶çš„ç”»è´¨ï¼Œå»é™¤å™ªç‚¹
    if w < 1500:
        try:
            # AI æ¨ç† (é‡ç»˜çº¿æ¡)
            img = sr.upsample(img)
            # æ›´æ–°å°ºå¯¸
            h, w = img.shape[:2]
        except Exception as e:
            print(f"   [AIè·³è¿‡] æ˜¾å­˜/å†…å­˜ä¸è¶³æˆ–æŠ¥é”™: {e}")

    # --- æ­¥éª¤ B: ç‰©ç†ç¼©æ”¾ (Super Sampling Downscale) ---
    # å°†åˆšåˆšå¯èƒ½è¢« AI æ”¾å¤§çš„é«˜æ¸…å›¾ï¼Œæˆ–è€…åŸæœ¬çš„é«˜æ¸…å›¾ï¼Œ
    # ä½¿ç”¨ "åŒºåŸŸæ’å€¼ (INTER_AREA)" ç¼©å°å› 1264px
    # INTER_AREA æ˜¯ç¼©å°å›¾ç‰‡æ—¶ç”»è´¨æœ€å¥½çš„ç®—æ³•ï¼Œèƒ½äº§ç”ŸæŠ—é”¯é½¿æ•ˆæœ
    if w > TARGET_WIDTH:
        ratio = TARGET_WIDTH / w
        new_h = int(h * ratio)
        img = cv2.resize(img, (TARGET_WIDTH, new_h), interpolation=cv2.INTER_AREA)

    # --- æ­¥éª¤ C: Gamma å¢å¼º (LUT) ---
    if GAMMA_VALUE != 1.0:
        # OpenCV çš„ LUT é€Ÿåº¦æå¿«
        lut = np.empty((1, 256), np.uint8)
        for i in range(256):
            lut[0, i] = np.clip(pow(i / 255.0, GAMMA_VALUE) * 255.0, 0, 255)
        img = cv2.LUT(img, lut)

    # --- æ­¥éª¤ D: ç¼–ç å¯¼å‡º ---
    # ä½¿ç”¨ OpenCV çš„ JPEG ç¼–ç 
    params = [cv2.IMWRITE_JPEG_QUALITY, JPEG_QUALITY]
    success, encoded_img = cv2.imencode('.jpg', img, params)
    
    return encoded_img.tobytes() if success else img_bytes

def run_deep_optimization(epub_path):
    print(f"   [2/2] æ­£åœ¨è¿›è¡Œç¥ç»ç½‘ç»œé‡ç»˜ (FSRCNN) + è¶…é‡‡æ ·ç¼©æ”¾...")
    temp_epub = epub_path + ".temp"
    original_size = os.path.getsize(epub_path)
    
    try:
        with zipfile.ZipFile(epub_path, 'r') as zin, zipfile.ZipFile(temp_epub, 'w', zipfile.ZIP_DEFLATED) as zout:
            file_list = zin.infolist()
            total = len(file_list)
            
            for i, item in enumerate(file_list):
                content = zin.read(item.filename)
                
                if item.filename.lower().endswith(('.jpg', '.jpeg', '.png')):
                    new_content = neural_enhance_image(content)
                    zout.writestr(item, new_content)
                else:
                    zout.writestr(item, content)
                
                # æ‰“å°è¿›åº¦ï¼Œå› ä¸ºAIå¤„ç†æ¯”è¾ƒæ…¢
                if i % 5 == 0:
                    print(f"      è¿›åº¦: {i}/{total} é¡µ processed...", end='\r')

        os.remove(epub_path)
        os.rename(temp_epub, epub_path)
        print("") # æ¢è¡Œ
        return original_size, os.path.getsize(epub_path)
        
    except Exception as e:
        print(f"âŒ ä¼˜åŒ–å‡ºé”™: {e}")
        if os.path.exists(temp_epub): os.remove(temp_epub)
        return original_size, original_size

def main():
    # 0. æ£€æŸ¥æ¨¡å‹
    check_and_download_model()

    if not os.path.exists(OUTPUT_DIR): os.makedirs(OUTPUT_DIR)
    files = [f for f in os.listdir(INPUT_DIR) if f.lower().endswith('.pdf')]
    
    if not files:
        print("âš ï¸  inputs æ–‡ä»¶å¤¹ä¸ºç©º")
        return

    print(f"ğŸ§¬ å¯åŠ¨å¼•æ“: ç¥ç»ç½‘ç»œè¶…åˆ† (FSRCNN) + ç‰©ç†æŠ—é”¯é½¿ç¼©æ”¾")
    print(f"âœ… ä¸“ä¸º Kindle 12ä»£ ä¼˜åŒ–")
    print("-" * 60)

    for file in files:
        start_time = time.time()
        input_path = os.path.join(INPUT_DIR, file)
        output_path = os.path.join(OUTPUT_DIR, os.path.splitext(file)[0] + ".epub")

        print(f"ğŸš€ å¤„ç†: {file}")
        
        if run_kcc_conversion(input_path, output_path):
            size_before, size_after = run_deep_optimization(output_path)
            
            mb_before = size_before / 1024 / 1024
            mb_after = size_after / 1024 / 1024
            reduction = (size_before - size_after) / size_before * 100
            
            print(f"âœ… å®Œæˆ! è€—æ—¶ {time.time()-start_time:.1f}s")
            print(f"   ğŸ“‰ {mb_before:.2f}MB -> {mb_after:.2f}MB (å‡å°äº† {reduction:.1f}%)")
        else:
            print("âŒ KCC è½¬æ¢å¤±è´¥")
        print("-" * 60)

if __name__ == "__main__":
    main()